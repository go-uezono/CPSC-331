\documentclass[10pt, 
a4paper, 
oneside, 
headinclude, footinclude, 
BCOR5mm]
{scrartcl}

\input{Structure.tex}
\hyphenation{Fortran hy-phen-ation}

%----Title and Authors----%
\title{\normalfont\spacedallcaps{CPSC 331: Data Structures, Algorithms, and their Analysis}}
\author{\spacedlowsmallcaps{Go Uezono}}

\begin{document}

%----Headers----%
\renewcommand{\sectionmark}[1]{\markright{\spacedlowsmallcaps{#1}}}
\lehead{\mbox{\llap{\small\thepage\kern1em\color{halfgray} \vline}\color{halfgray}\hspace{0.5em}\rightmark\hfil}}

\pagestyle{scrheadings}

%----Table of Contents----%
\maketitle
\setcounter{tocdepth}{2}
\tableofcontents
\listoffigures
\listoftables

\newpage
%Algorithmic Analysis%
\section{Algorithmic Analysis}
\subsection{Mathematical Induction}
\subsection{Loop Invariants}
\subsection{Bound Functions}

%-----------------------------------------------------------------------------------%
%Elementary Data Structures%
\section{Elementary Data Structures}

%-----------------------------------------------------------------------------------%
%--Lists--%
\subsection{Lists}

%-----------------------------------------------------------------------------------%
%--Stacks--%
\subsection{Stacks}

%-----------------------------------------------------------------------------------%
%--Queues--%
\subsection{Queues}

%-----------------------------------------------------------------------------------%
%Data Structures%
\section{Data Structures}
%--Binary Search--%
\subsection{Binary Search Trees}

\newpage

%-----------------------------------------------------------------------------------%
%--Red and Black Trees--%
\subsection{Red and Black Trees}
%----Properties----%
\subsubsection{Properties}
A \textbf{red-black tree} is a concrete implementation of a \textbf{self-balancing binary-search tree} (reference here) that automatically maintains balance. 
Giving each node their respective color ensures that no path is more than twice as long as any other, thus is able to maintain approximate balance.\
\begin{enumerate}
    \item Every node is {\color{red}red}/black
    \item Root must be black
    \item Leaves (\textit{null}) are black
    \begin{itemize}
        \item \textit{null} vertices contain no values, while other (interior) do
    \end{itemize}
    \item If a node is {\color{red}red}, then both its children are black
    \item For each node, all simple paths from the node to descendant leaves contain the same number of black nodes 
\end{enumerate}

%----Lemma----%
The following \textbf{lemma} shows why red-black trees make good search trees:
\begin{lemma}
    A red-black tree with $n$ internal nodes has height at most $2\log (n+1)$
\end{lemma}
\begin{proof}
    Start by showing subtree rooted at any ndoe $x$ x contains at least a $2^{bh(x)}-1$ internal nodes. We prove this by \textbf{mathematical induction} on the height of $x$.
    \begin{description}
        \item [\textbf{Claim:}] If height of $x=0$, then the leaf must be \textit{T.null}, and the subtree rooted at $x$ contains at least $2^{bh(x)}-1=2^0-1=0$ internal nodes.
        \begin{description}
            \item [\textbf{Inductive step:}] 
            \begin{itemize}
                \item Consider a node $x$ that has positive height and is an internal node with two children.
                \item Each \textit{child} has a black-height of either $bh(x)$ or $bh(x)-1$ (depending on whether it is {\color{red}red} or black respectively).
                \item Since height of a \textit{child} of $x$ is less than the height of $x$ itself, we can apply the \textbf{I.H} to conlude that:
                \begin{itemize}
                    \item Each child has at least $2^{bh(x)-1}-1$ internal nodes.
                \end{itemize}
            \end{itemize}
            \item Thus, subtree rooted at $x$ contains at least $$(2^{bh(x)-1}-1)+(2^{bh(x)-1}-1)+1$$ internal nodes, which proves the claim.
        \end{description} 
        \item To complete the proof, let $h$ be the height of thr tree. According to property 4 (reference above Properties), at least half the nodes from the root 
        to a leaf (not including the root) must be black.
        \item Consequently, the $bh$ of the root must be at least $h/2$; thus, $$n \geq 2^{h/2}-1$$
        \item Moving $1$ to the left side and taking log on both sides yields: $$\log(n+1) \geq h/2$$ or $$h \leq 2\log(n+1)$$
    \end{description}
\end{proof}

\newpage

%----Rotations----%
\subsubsection{Rotational Properties}
Search operations \textit{TREE-INSERT} and \textit{TREE-DELETE} take $O(\log n)$ time. Since modifications are done to the tree, we must change the color of some of the nodes.
\begin{definition}[\textbf{Rotation}]
    Local operation that preserves the binary-tree property. 
    \begin{itemize}
        \item \textbf{Left Rotation:} assume that its right child $y$ is not \textit{null} 
        \item \textbf{Right Rotation:} assume that its left child $y$ is not \textit{null}
        \begin{itemize}
            \item $x$ can be any node on the tree whose respective child is not \textit{null}
            \item Left/Right rotations "pivots" around the link from $x$ to $y$
            \item Makes $y$ the new root, $x$ as $y$'s left(right) child, $y$'s left(right) child as $x$'s right(left) child
        \end{itemize}
        \item Both L/R rotates run in $O(1)$ time
        \item Only pointers are changed, all attributes in a node remain the same
    \end{itemize}
\end{definition}

\begin{algorithm}
    \caption{Left-Rotate($T,x$)}

    $x = y.right$ \tcp*{set y}
    $x.right = y.left$ \tcp*{Turn y's left subtree into $x$'s right subtree}
    \uIf{$y.left \neq T.null$}
        {$y.left.p = x$\;}
    $y.p = x.p$\;
    \uIf{$x.p == T.null$}
        {$T.root = y$\;}
    \uElseIf{$x == x.p.left$}
        {$x.p.left = y$\;}
    \uElse{$x.p.right = y$\;}
    $y.left = x$\;
    $x.p = y$\;
\end{algorithm}

\newpage 

%----Insertion----%
\subsubsection{Insertion}
Inserting a node can be done in $O(\log n)$ time. Below is a pseudo-code that shows how insertion \textit{RB-INSERT} works:

\begin{algorithm}
    \caption{RB-INSERT$(T,z)$}
    \KwData{$z$ node to insert,}
    \BlankLine

    $y=T.null$\;
    $x=T.root$\;
    \While{$x \neq T.null$}
        {$y=x$\;        
        \eIf{$z.key < x.key$}
            {$x=x.left$\;}
        {$x=x.right$\;}}
    $z.p=y$\;
    \uIf{$y==T.null$}
        {$T.root=z$\;}
    \uElseIf{$z.key < y.key$}
        {$y.left=z$\;}
    \uElse{$y.right=z$\;}
    $z.left=T.null$\;
    $z.right=T.null$\;
    $z.color=T.RED$\;
    RB-INSERT$(T,z)$\;
    
\end{algorithm}

To ensure we preserve the {\color{red}red}-black properties, 
\newpage

%-----------------------------------------------------------------------------------%
%--Heaps--%
\subsection{Heaps}

%----Priority Queues----%
\subsubsection{Priority Queues} \label{subsubsec:prio-q}
\begin{itemize}
    \item Priority queues are \textbf{NOT} FIFO
    \item These queues are interested in removing items (dequeue) with the \textbf{highest priority}
    \item Assume that higher priority value (HPV) entails higher priority
    \begin{itemize}
        \item Not true in general (UNIX OS; smaller PV = higher priority)
    \end{itemize}
    \item Similar operations as the standard Queue ADT:
\end{itemize}

\begin{lstlisting}
    // Queue ADT
    public interface QueueADT<T> {
        public void enqueue(T item);
        public T dequeue(); // different implementation
        public boolean isEmpty();
        public boolean isFull();
    }
\end{lstlisting}
\BlankLine
\paragraph{\textbf{Priority Queue Implementations}}
\begin{itemize}
    \item \textbf{Lists}
    \begin{itemize}
        \item \textbf{Sorted} list by PV with \underbar{array implementation}
        \begin{itemize}
            \item \textit{Ascending order}: Remove \textbf{last} item
            \item \textit{Dequeue}: $O(1)$, \textit{n\textsuperscript{th}} element of the array to be removed
            \item \textit{Enqueue}: $O(n)$, needs to be sorted after enqueue
        \end{itemize}
        \item \textbf{Sorted} list by PV with \underbar{linked-list implementation} 
        \begin{itemize}
            \item \textit{Descending order}: Remove \textbf{first} item
            \item \textit{Ascending order}: Circular list implementation
            \item \textit{Dequeue}: $O(1)$
            \item \textit{Enqueue}: $O(n)$
        \end{itemize}
        \item \textbf{Unsorted} list
        \begin{itemize}
            \item \textit{Dequeue}: $O(n)$
            \item \textit{Enqueue}: $O(1)$
        \end{itemize}
    \end{itemize}
    \item \textbf{BST}
    \begin{itemize}
        \item \textit{Dequeue}: $O(\log(n))$ average-case, $O(n)$ worst-case 
        \item \textit{Enqueue}: $O(\log(n))$ average-case, $O(n)$ worst-case 
    \end{itemize}
    \item \textbf{Heaps}
    \begin{itemize}
        \item \textit{Dequeue}: $O(\log(n))$ worst-case 
        \item \textit{Enqueue}: $O(\log(n))$ worst-case 
    \end{itemize}
\end{itemize}
\newpage

%----Properties----%
\subsubsection{Properties}
A heap is a \textbf{complete} binary tree that satisfies the Heap Property:
\begin{itemize}
    \item Each node of a tree corresponds to an element of an array
    \begin{itemize}
        \item Always stored \textbf{contiguously}
        \begin{itemize}
            \item  If there are blanks, they are on the rightside of the array
            \item  Otherwise, no blanks inbetween indices
        \end{itemize}
    \end{itemize}
    \item It is of height \textit{h} and contains \textit{n} nodes
\end{itemize}

\begin{proof}
    Height \textit{h}
\end{proof}
\BlankLine

\paragraph{\textbf{Heap Properties}}
\begin{itemize}
    \item \textbf{Min Heap Property}
    \begin{itemize}
        \item Every node has a value $\leq$ than the value of its children
        \item Root of any subtree has the \textit{minimum} value in the subtree    
    \end{itemize}
    GIVE EXAMPLE
    \item \textbf{Max Heap Property}
    \begin{itemize}
        \item Every node has a value $\geq$ than the value of its children
        \item Root of any subtree has the \textit{maximum} value in the subtree
    \end{itemize}
    GIVE EXAMPLE
\end{itemize}

%----MaxHeap Class----%
\paragraph{\textbf{MaxHeap Class}}
Similar to the Queue ADT, differences in the enqueue and dequeue functions to maintain \textbf{heap} property
\begin{lstlisting}
    public class MaxHeap<T> {
        private T[] queue;
        private int size;

        public MaxHeap(Class<T> clazz, int maxSize) {
            queue = (T[]) Array.newInstance(clazz, maxSize);
            size = 0;
        }
        public boolean isEmpty() {
            return (size == 0);
        }
        public boolean isFull() {
            return (size == queue.length);
        }
    }
    // enqueue()/dequeue() functions shown later
\end{lstlisting}

%----Enqueue----%
\begin{definition}
    \textit{Enqueue}
    \begin{itemize}
        \item Must keep the tree \textbf{complete}
        \item Must keep the \textbf{max heap} property
        \item \textbf{Complexity of \textit{Enqueue}}
        \begin{itemize}
            \item \textit{Worst-case}: added node percolates from leaf to root
            \item Since the tree is \textbf{complete}, height is $O(\log(n))$
            \item Hence, \textbf{enqueue} is $O(\log(n))$
        \end{itemize}
    \end{itemize}
    \newpage
    Enqueue:
    \begin{lstlisting}
        public void enqueue(T item) {
            queue[size] = item;

            // Fix heap
            int loc = size;
            int parent = (loc - 1)/2;
            while (loc > 0 && queue[loc].compareTo(queue[parent]) > 0) {
                swap(loc, parent);
                loc = parent;
                parent = (loc - 1)/2;
            }
            size++;
        }
    \end{lstlisting}
    Correctness: \textbf{Loop Invariant} for Enqueue
    \begin{proof}
        
    \end{proof}
\end{definition}

%----Dequeue----%
\begin{definition}
    \textit{Dequeue}
    \begin{itemize}
        \item Must keep the tree \textbf{complete}
        \item Must keep the \textbf{max heap} property 
        \item \textbf{Complexity of \textit{Dequeue}}
        \begin{itemize}
            \item Deleted root "hole" always sinks to a leaf
            \item Since the tree is complete, height is $O(\log(n))$
            \item Hence, \textbf{dequeue} is $O(\log(n))$
        \end{itemize}
    \end{itemize}
    \textit{Dequeue}:
    \begin{lstlisting}
        public T dequeue() {
            T max = queue[0];
            queue[0] = queue[size - 1];
            sink(0);
            queue[size - 1] = null;
            size--;
            return max;
        }
    \end{lstlisting}
    Correctness: \textbf{Bound Function} for Dequeue
    \begin{proof}
        Prove that sink() maintains heap property
    \end{proof}
\end{definition}

\newpage
%-----------------------------------------------------------------------------------%
%--Hash Table--%
\subsection{Hash Table}

\newpage
%-----------------------------------------------------------------------------------%
%--Graphs--%
\subsection{Graphs}


\newpage
%-----------------------------------------------------------------------------------%
%--Dijkstra's Algorithm--%
\subsection{Dijkstra's Algorithm}

\newpage
%-----------------------------------------------------------------------------------%

%Sorting Algorithms%
\section{Sorting Algorithms}
%--Bubble Sort--%
\subsection{Bubble Sort}
Understand algorithm, prove correctness, time complexity 
\newpage
%-----------------------------------------------------------------------------------%
%--Selection Sort--%
\subsection{Selection Sort}
Understand algorithm, prove correctness, time complexity 
\newpage
%-----------------------------------------------------------------------------------%
%--Insertion Sort--%
\subsection{Insertion Sort}
Understand algorithm, prove correctness, time complexity 
\newpage
%-----------------------------------------------------------------------------------%
%--Heap Sort--%
\subsection{Heap Sort}
Understand algorithm, prove correctness, time complexity 
\newpage
%-----------------------------------------------------------------------------------%
%Advanced Sorting Algorithms
\section{Advanced Sorting Algorithms}
%--Merge Sort--%
\subsection{Merge Sort}
Understand algorithm, prove correctness, time complexity 
\newpage
%-----------------------------------------------------------------------------------%
%--Quick Sort--%
\subsection{Quick Sort}
Understand algorithm, prove correctness, time complexity 
\newpage
%-----------------------------------------------------------------------------------%

%Searching%
\section{Searching}
%--Linear Search--%
\subsection{Linear Search}
Algorithm, prove correctness, time complexity
\newpage
%-----------------------------------------------------------------------------------%
%--Binary Search--%
\subsection{Binary Search}
Algorithm, prove correctness, time complexity
\newpage
%-----------------------------------------------------------------------------------%

%Graph Traversal%
\section{Graph Traversal}
%--Depth-first Search--%
\subsection{Depth-First Search}
Develop algorithm, prove correctness, analyze time complexity, applications
\newpage
%-----------------------------------------------------------------------------------%
%--Breadth-first Search--%
\subsection{Breadth-First Search}
Develop algorithm, prove correctness, analyze time complexity, applications
\newpage
%-----------------------------------------------------------------------------------%

%%%%%%%%%%%%%%% DELETE %%%%%%%%%%%%%%%
% Methods
\section{Methods}

Test math notation: $\cos\pi=-1$ and $\alpha\omega$

Test Algorithm
\IncMargin{1em}
\begin{algorithm}
    \caption{Left-Rotate($T,x$)}
    \In{Test}
    \Out{Test}
    \BlankLine

    $i \gets 1$\;
    \eIf{condition}{then block}{else block}

\end{algorithm}\DecMargin{1em}


\begin{enumerate}
    \item 1st item in list
    \item 2nd item 
    \item 3rd
\end{enumerate}

% Subsections
\subsection{Test sub}

\paragraph{Description}
\paragraph{2nd Description}

\subsection{Math subsection}

\begin{equation}
    \cos^3 \theta = \frac{1}{4}\cos\theta + \frac{3}{4}\cos 3\theta
    \label{eq:refname2}
\end{equation}

\begin{definition}[Gauss]
    To a mathematician, it is obvious that
    $\int_{-\inf}^{+\inf} e^{-x^2}\, dx=\sqrt{pi}$.
\end{definition}

\begin{theorem}[Red and Black Trees]
    Red trees are better than black trees.
\end{theorem}

\begin{proof}
    We have that $\log(1)^2 = 2\log(1)$.
    We also have that $\log(-1)^2 = \log(1) = 0$.
    Then, $2\log(-1) = 0$, from which the proof.
\end{proof}

% Results and discussion
\section{Results and Discussion}

\subsection{Subsection}
Test subsec

\subsection{Subsubsection}
Test sub

\begin{description}
    \item[Word] Definition
    \item[Concept] Explanation
    \item[Idea] Text
\end{description}

Test Test

\begin{itemize}[noitemsep]
    \item First
    \item Second
    \item Third
\end{itemize}

\end{document}
